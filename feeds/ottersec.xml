<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
  <title type="text">OtterSec Blog</title>
  <link rel="alternate" type="text/html" href="https://osec.io/blog"/>
  <link rel="self" type="application/atom+xml" href="http://10.0.0.124:3044/?action=display&amp;bridge=CSSLostDateBridge&amp;home_page=https%3A%2F%2Fosec.io%2Fblog&amp;url_selector=.outline-hover-card+a&amp;url_pattern=%2Fblog%2F.*&amp;content_selector=main&amp;content_cleanup=h3%2C.eyebrow%2C.otter-button%2C.table-of-contents%2C+.pt-20%2C+script&amp;title_cleanup=&amp;date_selector=.eyebrow&amp;date_format=M+j%2C+Y&amp;date_selector_index=&amp;author_selector=&amp;remove_styling=on&amp;remove_markup=on&amp;limit=3&amp;_cache_timeout=3600&amp;format=Atom"/>
  <icon>https://github.com/RSS-Bridge/rss-bridge/favicon.ico</icon>
  <logo>https://github.com/RSS-Bridge/rss-bridge/favicon.ico</logo>
  <id>http://10.0.0.124:3044/?action=display&amp;bridge=CSSLostDateBridge&amp;home_page=https%3A%2F%2Fosec.io%2Fblog&amp;url_selector=.outline-hover-card+a&amp;url_pattern=%2Fblog%2F.*&amp;content_selector=main&amp;content_cleanup=h3%2C.eyebrow%2C.otter-button%2C.table-of-contents%2C+.pt-20%2C+script&amp;title_cleanup=&amp;date_selector=.eyebrow&amp;date_format=M+j%2C+Y&amp;date_selector_index=&amp;author_selector=&amp;remove_styling=on&amp;remove_markup=on&amp;limit=3&amp;_cache_timeout=3600&amp;format=Atom</id>
  <updated>2025-04-11T22:08:26+00:00</updated>
  <author>
    <name>RSS-Bridge</name>
  </author>
  <entry>
    <title type="html">Subverting Web2 Authentication in Web3</title>
    <published>2025-03-07T22:08:26+00:00</published>
    <updated>2025-03-07T22:08:26+00:00</updated>
    <id>https://osec.io</id>
    <link rel="alternate" type="text/html" href="https://osec.io"/>
    <content type="html">Web3 authentication uses cryptographic signatures and wallets, but Web2 auth integrations can introduce hidden risks. We explore vulnerabilities like OAuth logic exploits, Supabase misconfigurations, and OAuth abuse in localhost setups.Bruno Halltari3/7/2025Caue Obici3/7/2025Authentication serves as a cornerstone of secure interactions in Web3, enabling access control, user identity verification, and transaction integrity. Unlike traditional Web2 systems, which often rely on centralized databases and password-based mechanisms, Web3 systems adopt decentralized identifiers (DIDs), cryptographic signatures, and wallet-based authentication. However, there are many applications that still use Web2-based authentication providers to improve the user experience.In our research, we focused on Web3 applications that rely on Web2-based authentication methods. Specifically, we analyzed the authentication flows of these applications and identified a lesser-known class of vulnerabilities.In this article, we will discuss three cases we discovered:OAuth Logic Vulnerability on an Authentication ProviderSupabase user_metadata misconfigurationOAuth abuse in localhost development environmentAbusing OAuth Authentication LogicDuring our research, we initially identified some bugs in applications. However, these were mostly simple and well-known issues, so we decided to focus on vulnerabilities within authentication providers themselves.Web3Auth is a tool designed to simplify the login process for Web3 applications, eliminating the need for users to manage complex wallet setups or memorize lengthy passwords. One of its products, Web3Auth PnP (Plug and Play), supports OAuth2 authentication using Google. The product employs a sophisticated authentication flow and infrastructure to maintain seamless integration with dApps.The Web3Auth PnP authentication flow involves a web session server that stores authentication parameters and configurations. Below is a diagram illustrating how the authentication process works:After the final redirect back to the dApp,  the application can use the secret token to authenticate with the service identified by the client_id. This design ensures that you cannot use the token to authenticate against any unauthorized application.Additionally, it is important to note that each dApp has a whitelist of redirect URLs. The /start validates the redirect_url against the configured whitelist to ensure it matches one of the allowed URLs.The session server employs cryptography to securely send and receive authentication parameters. The cryptographic key is derived from the sessionId  sent in the GET parameter to the /start. Since the sessionId can be controlled, it allows us to send and receive data from the session server.As shown in the diagram, the configuration data from the session server is validated only during the /start and later used in the /end enpoint. This introduces a potential race condition that can be exploited if an attacker manages to modify the parameters after  validation (/start) but before  use (/end).To exploit this race condition,  an attacker-controlled website can initiate the authentication flow normally. Then, it can send another request to the session server with the same sessionId but with modified malicious parameters.What can be modified to achieve something impactful?The answer is quite simple if you understand how OAuth works. The attacker can simply change the redirect_uri parameter to point to their own website and leak the secret token from the query string. With the secret token, they can authenticate against the application defined by client_id.Using this exploit, we were able to create a website capable of taking over the accounts of victims who followed the standard OAuth flow.The vulnerability was reported and remediated on the same day (super quickly!). However, we found that the fix was not backported to older versions.To bypass the fix we were able to change the version in the URL:https://auth.web3auth.io/v8/start (latest version)https://auth.web3auth.io/v6/start (bypass)We reported this issue, and it was addressed just as quickly!Supabase metadata manipulationSupabase is a Backend-as-a-Service (BaaS) platform that provides authentication, database, and real-time APIs. The authentication process begins when a user registers or logs in. Supabase generates a JWT for the authenticated user, embedding claims such as the user ID, roles, and additional metadata (either user-provided or system-generated). This token is then returned to the client and used for subsequent API requests, during which the server validates the JWT to confirm the user’s identity and permissions.In one of our clients&amp;#39; systems, we discovered a vulnerability that allowed the inclusion of custom fields, such as user_metadata and identity_data, in a signup request by manipulating the input inside the &amp;quot;data&amp;quot;: {} structure. These fields were then directly reflected in the issued JWT without validation.For example, an attacker could send a signup request with arbitrary data, such as &amp;quot;role&amp;quot;: &amp;quot;admin&amp;quot; or &amp;quot;email_verified&amp;quot;: true, which would subsequently be included in the JWT claims. Additionally, it was possible to insert arbitrary fields beyond typical inputs, such as &amp;quot;test&amp;quot;: &amp;quot;test&amp;quot;, enabling us to inject arbitrary data into the final JWT token.In this example we are controlling the &amp;quot;role&amp;quot; field within the user metadata. If the application manage roles using the metadata, it would be vulnerable to a privilege escalation since anyone could inject any role there.The attacker could subsequently log in on the main platform, retrieve the token, and verify that their injected parameters persist in the JWT by submitting it to a verification endpoint. This happens because a function parseSupaBase was parsing and verifying everything generated by the JWT supabase token.function parseSupaBase(token) {     try {         const [header, payload, signature] = token.split(&amp;#39;.&amp;#39;);         const decodedHeader = JSON.parse(atob(header));         const decodedPayload = JSON.parse(atob(payload));         return { header: decodedHeader, payload: decodedPayload, signature };     } catch (error) {         console.error(&amp;#39;Error parsing token:&amp;#39;, error);         return null;     } } Developers should avoid trusting input from their Supabase custom domain. Row-Level Security (RLS) on Supabase should be enforced, plus important and private fields should be defined in app_metadata. These fields must be strictly validated at every step of their creation and update processes.OAuth in development environmentsAfter watching a talk by Luan Herrera on exploiting the logic of desktop apps that use OAuth for authentication (specifically using a localhost server), we noticed that many of our customers also permitted localhost within the redirect_uri parameter during the OAuth flow.Herrera&amp;#39;s research highlights that if localhost is allowed as a redirect URI, it is generally not exploitable in a desktop environment because impersonating localhost without Remote Code Execution (RCE) is impossible. However, the scenario changes in a mobile environment, where it is feasible to open a localhost web server using a malicious app, making exploitation possible.In one of our client&amp;#39;s implementations, we identified that localhost:3000 was permitted. The exploitation method is the same as demonstrated in Herrera&amp;#39;s talk. However, we observed that localhost servers are frequently used and whitelisted by developers, not only for desktop applications but also for testing and development environments.For the exploitation, the final Google OAuth URL was constructed as follows:https://accounts.google.com/o/oauth2/v2/auth?client_id=redacted&amp;amp;scope=openid%20email%20profile&amp;amp;response_type=code&amp;amp;redirect_uri=http%3A%2F%2Flocalhost%3A3000%2Fapi%2Fauth%2Fcallback%2Fgoogle&amp;amp;prompt=none&amp;amp;access_type=offline&amp;amp;state=2UTJ8naHVglSQQupa1jw1lugsaZr8f5M9hxZp7bxISM&amp;amp;code_challenge=e6_Onj804xizwJzVT5Pf8luKPbtLV-EJssR7I58UQp8&amp;amp;code_challenge_method=S256&amp;amp;service=lso&amp;amp;o2v=2&amp;amp;ddm=1&amp;amp;flowName=GeneralOAuthFlow Since there was no public exploit, we also created a proof of concept demonstrating how a malicious APK can be created to steal the OAuth token simply by opening the malicious app. This occurs without any user interaction and results in account takeover.class MainActivity : AppCompatActivity() {      override fun onCreate(savedInstanceState: Bundle?) {         super.onCreate(savedInstanceState)          // Start the Ktor web server         CoroutineScope(Dispatchers.IO).launch {             try {                 startWebServer()                 Log.d(&amp;quot;WebServer&amp;quot;, &amp;quot;Server started on http://localhost:3000&amp;quot;)             } catch (e: Exception) {                 Log.e(&amp;quot;WebServer&amp;quot;, &amp;quot;Error starting server: ${e.message}&amp;quot;, e)             }         }          // Open the Google OAuth page         val googleOAuthUrl = &amp;quot;https://accounts.google.com/o/oauth2/v2/auth?client_id=redacted&amp;amp;scope=openid%20email%20profile&amp;amp;response_type=code&amp;amp;redirect_uri=http%3A%2F%2Flocalhost%3A3000%2Fapi%2Fauth%2Fcallback%2Fgoogle&amp;amp;prompt=none&amp;amp;access_type=offline&amp;amp;state=2UTJ8naHVglSQQupa1jw1lugsaZr8f5M9hxZp7bxISM&amp;amp;code_challenge=e6_Onj804xizwJzVT5Pf8luKPbtLV-EJssR7I58UQp8&amp;amp;code_challenge_method=S256&amp;amp;service=lso&amp;amp;o2v=2&amp;amp;ddm=1&amp;amp;flowName=GeneralOAuthFlow&amp;quot;         val browserIntent = Intent(Intent.ACTION_VIEW, Uri.parse(googleOAuthUrl))         startActivity(browserIntent)     }      private fun startWebServer() {         embeddedServer(CIO, port = 3000) {             routing {                 get(&amp;quot;{...}&amp;quot;) {                     call.respondHtml {                         head {                             meta(charset = &amp;quot;UTF-8&amp;quot;)                             meta(name = &amp;quot;viewport&amp;quot;, content = &amp;quot;width=device-width, initial-scale=1.0&amp;quot;)                             title(&amp;quot;OAuth Redirect&amp;quot;)                         }                         body {                             h1 { +&amp;quot;Google OAuth Redirect&amp;quot; }                             script {                                 +&amp;quot;document.body.innerText = location.search;&amp;quot;                             }                         }                     }                 }             }         }.start(wait = true)     } } The code essentially creates a localhost web server and redirects the user to the OAuth authorization screen, which can be automatically bypassed under certain conditionswithout any user interaction. Once the authorization process is completed, the OAuth flow redirects the user back to the localhost server, including the secret authorization token in the query string.Since the attacker controls the localhost server, they can intercept and extract the token, enabling them to take over the victim&amp;#39;s account.As a mitigation measure, it is crucial to ensure that localhost servers are not whitelisted in the OAuth redirect_uri parameter. If whitelisting localhost is necessary due to specific business requirements, a custom solution must be carefully designed and implemented to safeguard the account security of all users.ConclusionIn this article, we explored three lesser-known classes of vulnerabilities present in Web2 authentication flows utilized by Web3 dApps, shedding light on critical but often overlooked security risks. Authentication processes are inherently complex, and this complexity leaves room for vulnerabilities to persist unnoticed in applications.By uncovering and analyzing these vulnerabilities, we aim to stress the necessity of adopting a robust, holistic approach to authentication security. As Web3 continues to evolve, bridging the gap between traditional Web2 frameworks and the decentralized Web3 ecosystem is not just an opportunity but an imperative to safeguard users and their data.html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}</content>
    <link rel="enclosure" type="image/jpeg" href="https://osec.io/posts/web2-in-web3/title.jpg"/>
  </entry>
  <entry>
    <title type="html">Solana Multisig Security</title>
    <published>2025-02-22T22:08:26+00:00</published>
    <updated>2025-02-22T22:08:26+00:00</updated>
    <id>https://osec.io</id>
    <link rel="alternate" type="text/html" href="https://osec.io"/>
    <content type="html">What can teams do if their multisig signers are compromised? We explore Solana&amp;#39;s transaction signing model and present a procedure for safe signing in the presence of malicious signers on Solana.Robert Chen2/22/2025The Bybit hack raises an interesting question: what can teams do if their signers are compromised?Solana SignaturesWe first need to understand how Solana signatures work. There are two ways to sign a Solana transaction.The most straightforward is with a &amp;quot;recent blockhash&amp;quot;. From the docs:During transaction processing, Solana Validators will check if each transaction&amp;#39;s recent blockhash is recorded within the most recent 151 stored hashes (aka &amp;quot;max processing age&amp;quot;). If the transaction&amp;#39;s recent blockhash is older than this max processing age, the transaction is not processed.The actual constant is defined here.// The maximum age of a blockhash that will be accepted by the leader pub const MAX_PROCESSING_AGE: usize = MAX_RECENT_BLOCKHASHES / 2; For those curious, the logic starts here and is quite straightforward to follow, ending in a is_hash_index_valid check.fn is_hash_index_valid(last_hash_index: u64, max_age: usize, hash_index: u64) -&amp;gt; bool {     last_hash_index - hash_index &amp;lt;= max_age as u64 } One important consequence is that any signed transaction has a natural expiration of around a few minutes.Since slots (aka the time period a validator can produce a block) are configured to last about 400ms, but may fluctuate between 400ms and 600ms, a given blockhash can only be used by transactions for about 60 to 90 seconds before it will be considered expired by the runtime.This means an attacker must use a malicious signed transaction within a short timeframe.The second type of signature is a durable nonce. These were created to solve the very feature (or problem) mentioned above: short expiration time.durable nonces provide an opportunity to create and sign a transaction that can be submitted at any point in the future, and much more. This opens up a wide range of use cases that are otherwise not possible or too difficult to implementIf we examine the code for recent blockhash validation, we can also see the handling for durable nonces.    let recent_blockhash = tx.message().recent_blockhash();     if let Some(hash_info) = hash_queue.get_hash_info_if_valid(recent_blockhash, max_age) {         Ok(CheckedTransactionDetails {             nonce: None,             lamports_per_signature: hash_info.lamports_per_signature(),         })     } else if let Some((nonce, previous_lamports_per_signature)) = self         .check_load_and_advance_message_nonce_account(             tx.message(),             next_durable_nonce,             next_lamports_per_signature,         )     {         Ok(CheckedTransactionDetails {             nonce: Some(nonce),             lamports_per_signature: previous_lamports_per_signature,         })     } else {         error_counters.blockhash_not_found += 1;         Err(TransactionError::BlockhashNotFound)     } The documentation does a good job of explaining how they work.Durable Transaction Nonces, which are 32-byte in length (usually represented as base58 encoded strings), are used in place of recent blockhashes to make every transaction unique (to avoid double-spending) while removing the mortality on the unexecuted transaction.Durable nonces are created and managed by the system program. They don&amp;#39;t have a fixed PDA, so each account can have multiple associated nonces.After a durable nonce is used, it&amp;#39;ll be &amp;quot;advanced&amp;quot; to preventing replay attacks. The new nonce is calculated based on the current blockhash, and cannot be predicted in advance.    let hash_queue = self.blockhash_queue.read().unwrap();     let last_blockhash = hash_queue.last_hash();     let next_durable_nonce = DurableNonce::from_blockhash(&amp;amp;last_blockhash); This has an important consequence for our threat model. Unlike recent blockhash transactions, durable nonce transactions can be saved and reused.Threat ModelLet&amp;#39;s consider a simplified form of the original question.We have a N/M multisigSigners are unable to see what they&amp;#39;re signing, both with respect to content and quantity of signatures. This is roughly equivalent to blind signing transactions.We can accurately query chain state.Can we safely sign transactions?One observation is that this problem is very hard to solve with durable nonces. By signing durable nonce transactions, an attacker could collect signatures and replay them at some indeterminite future point.Durable nonces require an onchain account, and it&amp;#39;s possible to use a getProgramAccounts call to validate if your signer has an associated durable nonce.const connection = new Connection(clusterApiUrl(&amp;#39;testnet&amp;#39;)); const nonceAccounts = await connection.getProgramAccounts(   // The system program owns all nonce accounts.   SYSTEM_PROGRAM_ADDRESS,   {     filters: [       {         // Nonce accounts are exactly 80 bytes long         dataSize: 80,       },       {         // The authority&amp;#39;s 32-byte public key is written         // into bytes 8-40 of the nonce&amp;#39;s account data.         memcmp: {           bytes: AUTHORITY_PUBLIC_KEY.toBase58(),           offset: 8,         },       },     ],   } ); Unfortunately this is not sufficient1. A transaction may have multiple signers, and an attacker could use their own durable nonce fee-payer. This means our problem as defined above is unfortunately unsolvable.    let instruction = system_instruction::transfer(&amp;amp;from, &amp;amp;ledger_base_pubkey, 42);     let message =         Message::new_with_nonce(vec![instruction], Some(&amp;amp;evil_nonce_authority), &amp;amp;nonce_account, &amp;amp;evil_nonce_authority)             .serialize(); Luckily, it is tractable with a small modification. What if the signer is allowed to observe the fee-payer on the transaction? For example, Ledger logs the fee-payer here.bool print_config_show_authority(const PrintConfig* print_config, const Pubkey* authority) {     return print_config-&amp;gt;expert_mode || !pubkeys_equal(print_config-&amp;gt;signer_pubkey, authority); } Let&amp;#39;s say we&amp;#39;ve determined our signer has no associated nonce accounts. If our pubkey is the fee-payer on the new proposed transaction, we can know for sure that the transaction does not use durable nonces!Without durable nonces, the problem becomes much easier to solve. After waiting enough time, there&amp;#39;ll be a point where all previously signed transactions will be expired. If we see no unexpected transactions, that means we&amp;#39;re safe.We can then use the following procedure.Ensure all signers have no durable nonce accounts.The first signer signs and submits the transaction.Wait two minutes for all recent blockhashes to expire.Observe recent transactions associated with the signer to ensure nothing unexpected is submitted.Repeat steps 2 to 4 for each signerBeyondSolana&amp;#39;s signature model is unique. What can protocols do if they&amp;#39;re deploying on blockchains without these unique properties? The most important constraint is observability. There must be a way you can see what you&amp;#39;re signing, either while signing or implicitly after the fact.For example, pcaversaccio wrote a tool to validate Safe transaction hashes. As the space matures, we hope more open source tooling will come to light.FootnotesThe original version of this blog post did not consider a malicious fee-payer. Thanks to @PierreArowana for pointing this out to me. ↩html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}</content>
    <link rel="enclosure" type="image/png" href="https://osec.io/posts/multisig-security/title.png"/>
  </entry>
  <entry>
    <title type="html">Hitchhiker's Guide to Aptos Fungible Assets</title>
    <published>2025-02-10T22:08:26+00:00</published>
    <updated>2025-02-10T22:08:26+00:00</updated>
    <id>https://osec.io</id>
    <link rel="alternate" type="text/html" href="https://osec.io"/>
    <content type="html">We take a deep dive into Aptos’ implementation of fungible assets, exploring the intricacies hidden within its functions, objects, and interactions. While the Fungible Asset model was designed to address the limitations and security flaws of the legacy Coin standard, it also introduced new challenges and vulnerabilities that developers should be aware of.Aptos’ fungible asset model is a complex component of its ecosystem, designed to address the limitations of its predecessor — the coin standard. While the new model aims to enhance functionality and security, it also comes with its own set of challenges.In this blog post, we&amp;#39;ll closely examine Aptos&amp;#39;s coin and fungible asset models, exploring their history and connection. We will examine key aspects of the fungible asset framework, including real-world examples of vulnerabilities that were identified and addressed, with the goal of improving security and reliability — all to help you build more secure and reliable applications.ImportantAll issues mentioned were identified and addressed during Aptos&amp;#39; rigorous pre-release audits, demonstrating the project&amp;#39;s dedication to delivering a robust and secure environment from day one.Aptos Coin standardIn the beginning, Aptos used Coin. It is still in use, although it is now considered &amp;quot;legacy&amp;quot;. Coin is defined in Aptos as follows:struct Coin&amp;lt;phantom CoinType&amp;gt; has store {     value: u64, } Aptos distinguishes coins by their type (CoinType) at compile time. For example, Coin&amp;lt;Otter&amp;gt; and Coin&amp;lt;Weasel&amp;gt; represent different coins, and you cannot pass a Coin&amp;lt;Weasel&amp;gt; to a function expecting Coin&amp;lt;Otter&amp;gt;.The type signature reveals why Coin has become a legacy standard. Coin has only the store ability and uses a CoinStore wrapper to store the coin and metadata:struct CoinStore&amp;lt;phantom CoinType&amp;gt; has key {     coin: Coin&amp;lt;CoinType&amp;gt;,     frozen: bool,     deposit_events: EventHandle&amp;lt;DepositEvent&amp;gt;,     withdraw_events: EventHandle&amp;lt;WithdrawEvent&amp;gt;, } However, an astute reader would note that this isn&amp;#39;t the only place a Coin can be stored. You can create your own Coin wallet, which could look like this:struct DefinitelyLegitCoinStore&amp;lt;phantom CoinType&amp;gt; has key {     coin: Coin&amp;lt;CoinType&amp;gt; } CoinStore includes a frozen field, allowing the issuer to block transfers to and from the store. CoinStore is also required for a burn_from operation, which withdraws the coin from the store and destroys it. Freezing and burning operations are essential i.e. for stablecoin issuers, using them as compliance tools to prevent unauthorized or illegal transactions and adhere to legal orders. Being able to bypass these restrictions with a custom wallet is an issue and can lead to severe consequences.Storing coin in a custom wallet is also a problem in terms of off-chain observability, as finding the stored coins in such setup is a difficult task. This is how the fungible asset AIP-21 summarizes the coin problems:... coin module has been deemed insufficient for current and future needs due to the rigidity of Move structs and the inherently poor extensibility.The existing Coin struct leverages the store ability allowing for assets on-chain to become untraceable. Creating challenges to off-chain observability and on-chain management, such as freezing or burning.And declares, that:Fungible assets addresses these issues.Let&amp;#39;s find out whether this is indeed the case.The fungible assetsAptos designed fungible assets as a new token standard to solve these problems. A FungibleAsset uses the hot-potato pattern:struct FungibleAsset {     metadata: Object&amp;lt;Metadata&amp;gt;,     amount: u64, } Unlike Coin, FungibleAsset types are defined at runtime through the Metadata field. This change was meant to enhance extensibility:An object can have other resources attached to provide additional context. For example, the metadata could define a gem of a given type, color, quality, and rarity, where ownership indicates the quantity or total weight owned of that type of gem.An important implication is that functions accepting FungibleAssets must verify the metadata to ensure valid assets.Let&amp;#39;s consider a possible implementation of a protocol that takes in assets.public fun deposit&amp;lt;T: key&amp;gt;(     sender: &amp;amp;signer, fa: FungibleAsset ) acquires [...] {     assert_not_paused();          let fa_amount = fungible_asset::amount(&amp;amp;fa);     let sender_address = address_of(sender);     check_compliance(fa_amount, sender_address);          increase_deposit(get_vault(sender_address), fa_amount);          primary_fungible_store::deposit(global_vault_address(), fa);          event::emit(Deposit {sender_address, fa_amount}) } Do you see any problems here? The application does not validate or differentiate fungible assets using their metadata, which causes all fungible asset deposits to be treated as identical.While these bugs aren&amp;#39;t partiularly complex, they do represent an additional vulnerability class that must be checked for.Fungible storesAs mentioned, fungible assets are hot potatoes, meaning they must be destroyed after each transaction. If they lack abilities, how can they be used?Meet the FungibleStore.struct FungibleStore has key {     metadata: Object&amp;lt;Metadata&amp;gt;,     balance: u64,     frozen: bool, } FungibleStore manages balances and metadata instead of holding the actual FungibleAsset (it can&amp;#39;t because FungibleAsset doesn&amp;#39;t have store). Withdrawals create temporary FungibleAsset resources, while deposits destroy them and update the balance. This design prevents freezing bypasses and improves observability.A curious reader might wonder, is there any other way to create or destroy a FungibleAsset besides withdrawing, depositing or minting it? There is — anyone can create and destroy a zero-value FungibleAsset.public fun destroy_zero(fungible_asset: FungibleAsset) {     let FungibleAsset { amount, metadata: _ } = fungible_asset;     assert!(amount == 0, error::invalid_argument(EAMOUNT_IS_NOT_ZERO)); }  public fun zero&amp;lt;T: key&amp;gt;(metadata: Object&amp;lt;T&amp;gt;): FungibleAsset {     FungibleAsset {         metadata: object::convert(metadata),         amount: 0,     } } In theory, this shouldn’t pose a problem. After all, having zero of something doesn’t exactly qualify as ownership.In practice, the ability to freely mint and burn zero FungibleAssets of any type could present a significant risk. During our reviews, we enountered many protocols that did not account for this possibility, leading to arithmetic errors, DoS logic bugs or inaccurate calculations. Keep in mind that edge case, we&amp;#39;ll come back to this.FungibleStores in comparison to CoinStores are not unique. Each user can have multiple FungibleStore objects for a given token!A primary fungible store is maintained via the aptly named primary_fungible_store module. It&amp;#39;s &amp;quot;primary&amp;quot; because of its deterministic location, which is calculated using the owner and the fungible asset&amp;#39;s Metadata addresses. Users can also create a number of &amp;quot;secondary&amp;quot; fungible stores by themselves.One key feature of the primary fungible stores is their permissionless creation. This can lead to surprising denial of service bugs!public entry fun register(     user: &amp;amp;signer, [...] ) acquires [...] {     [...]     let wallet_store = create_primary_store(signer::address_of(sender), get_metadata());     [...] } The create_primary_store function can introduce DoS vulnerabilities because it aborts if the store already exists. Using ensure_primary_store_exists is recommended to avoid such issues.Fungible assets and objectsThe fungible asset standard is not a standalone module. It has heavy dependencies on a sibling module, the Object module, introduced in AIP-10.AIP-21 proposes a standard for Fungible Assets (FA) using Move Objects. In this model, any on-chain asset represented as an object can also be expressed as a fungible asset allowing for a single object to be represented by many distinct, yet interchangeable units of ownership.These two modules are closely intertwined, and their connection can be surprisingly intricate.To create a fungible resource, an undeletable object must first be created. &amp;quot;Undeletable&amp;quot; means, that it&amp;#39;s not possible to get a permission to delete it. This is verified in fungible_asset::add_fungibility:assert!(!object::can_generate_delete_ref(constructor_ref), error::invalid_argument(EOBJECT_IS_DELETABLE)); This object serves as the foundation for ownership tokens in the form of a FungibleAsset. This means that allowing it to be deletable wouldn&amp;#39;t make sense and would impact the usability of such fungible assets, restricting users from accessing critical functionalities such as creating new stores. In the past the fungible_asset::add_fungibility lacked this assert, which we discovered and reported.fungible_asset::add_fungibility transfers the Metadata and associated resources to this new object. After that, with the appropriate permissions, the FungibleAsset can be minted, representing a share of ownership in that object./// Make an existing object fungible by adding the Metadata resource. public fun add_fungibility(     [...] ): Object&amp;lt;Metadata&amp;gt; {     [...]     move_to(metadata_object_signer,         Metadata {             name,             symbol,             decimals,             icon_uri,             project_uri,         }     ); [...] } Deletions can be a big issue even when dealing with objects that are eligible for deletion. For example, a FungibleStore is also an object, and a &amp;quot;secondary&amp;quot; FungibleStore can be created as deletable if empty. The catch is that deletion can occur both at the fungible asset level and at the object level.//Fungible asset public fun remove_store(delete_ref: &amp;amp;DeleteRef)  //Object public fun delete(ref: DeleteRef) When object::delete removes the Object from a FungibleStore object, the FungibleStore resource becomes permanently undeletable. This is because remove_store can&amp;#39;t create an Object&amp;lt;FungibleStore&amp;gt; without an Object underneath, causing the operation to fail.public fun remove_store(delete_ref: &amp;amp;DeleteRef) acquires [...] {     let store = &amp;amp;object::object_from_delete_ref&amp;lt;FungibleStore&amp;gt;(delete_ref);     [...] } In addition, such &amp;quot;deleted&amp;quot; FungibleStore objects remain at least partially operable. For instance, fungible_asset::deposit does not check the Object existence.Each object has an owner. Fungible assets rely on the Object ownership model. For example, during a withdrawal operation, the signer is validated using object::owns to confirm ownership of the FungibleStore object.public(friend) fun withdraw_sanity_check&amp;lt;T: key&amp;gt;(     owner: &amp;amp;signer,     store: Object&amp;lt;T&amp;gt;,     abort_on_dispatch: bool, ) acquires FungibleStore, DispatchFunctionStore {     assert!(object::owns(store, signer::address_of(owner)), error::permission_denied(ENOT_STORE_OWNER));     [...] } The thing to note is that defining ownership with object::owns can be tricky. The burn function was one of the reasons behind that. It allowed changing the object&amp;#39;s owner to the BURN_ADDRESS while bypassing transfer restrictions:public entry fun burn&amp;lt;T: key&amp;gt;(owner: &amp;amp;signer, object: Object&amp;lt;T&amp;gt;) acquires ObjectCore {     let original_owner = signer::address_of(owner);     assert!(is_owner(object, original_owner), error::permission_denied(ENOT_OBJECT_OWNER));     let object_addr = object.inner;     move_to(&amp;amp;create_signer(object_addr), TombStone { original_owner });     transfer_raw_inner(object_addr, BURN_ADDRESS); } unburn is a way to restore the previous object owner. In a past audit, this mechanism could be exploited to bypass fungible store owner blacklisting by temporarily setting ownership to the unblacklisted BURN_ADDRESS. AIP-99 is a proposal to roll back the burn feature, but previously burned objects will remain restorable.This AIP-99 seeks to disable safe object burn, as it caused extra complexity, and sometimes unexpected consequences. As a result of this AIP, users will still be able to unburn their burnt objects, but will not be able to burn any new objects.Another important thing is that fungible_asset::set_untransferable can be used to make all new FungibleStores for this asset untransferable, preventing ownership changes. However, this restriction doesn&amp;#39;t apply to the parent object, allowing a transferable parent to be moved even if it owns a non-transferable FungibleStore.Do we need to care about this case? We do, because ownership is transitive. If entity X owns an object that owns a FungibleStore, X can withdraw from that store. This is because fungible_asset::withdraw uses object::owns to verify both direct and indirect ownership of the FungibleStore object.fun verify_ungated_and_descendant(owner: address, destination: address) acquires ObjectCore {         [...]     while (owner != current_address) {         count = count + 1;         [...]         assert!(             exists&amp;lt;ObjectCore&amp;gt;(current_address),             error::permission_denied(ENOT_OBJECT_OWNER),         );         let object = borrow_global&amp;lt;ObjectCore&amp;gt;(current_address);         current_address = object.owner;     }; } This could allow for bypassing assumptions about FungibleStore true ownership and its non-transferability.public fun untransferable_transfer(caller: &amp;amp;signer, receipient: address) {     let constructor_ref = object::create_object(signer::address_of(caller));     let object_addr = object::address_from_constructor_ref(&amp;amp;constructor_ref);     let store = primary_fungible_store::ensure_primary_store_exists(object_addr, get_metadata());      object::transfer_raw(caller, object_addr, receipient);     //receipient can interact with store by using their signer } The ownership transfer issue also showed up during our review of the fungible asset standard, where we identified an interesting edge case involving the transfer of a non-transferable fungible store.public fun transfer_with_ref(ref: LinearTransferRef, to: address) acquires ObjectCore {     assert!(!exists&amp;lt;Untransferable&amp;gt;(ref.self), error::permission_denied(ENOT_MOVABLE));     let object = borrow_global_mut&amp;lt;ObjectCore&amp;gt;(ref.self);     assert!(         object.owner == ref.owner,         error::permission_denied(ENOT_OBJECT_OWNER),     );          [...]          object.owner = to; } A user could exploit this by creating an object and a transfer permission, burning the object (changing its ownership to the BURN_ADDRESS), transferring it to another user, and then registering a non-transferable fungible store with that object. While the store could no longer be moved using the owner&amp;#39;s signer or the transfer permission due to non-transferable restrictions, it could be unburned to restore the original ownership!References are a permission type resource that authenticate a caller for security-critical operations. Refs are based on the Object model, but they are also adapted by fungible assets. Some of these are defined by the Object itself, while others are created through the fungible asset module. What&amp;#39;s more, some are shared between them, while others appear shared but aren’t.Let&amp;#39;s get back to the FungibleStore deletion example. Both object::delete and fungible_asset::remove_store use the same object-specific DeleteRef permission. It can be created only during object creation. There is no separate DeleteRef for fungible assets.//Fungible asset public fun remove_store(delete_ref: &amp;amp;DeleteRef)  //Object public fun delete(ref: DeleteRef) On the other hand, the &amp;quot;frozen&amp;quot; status of a FungibleStore is toggled using a TransferRef, which is defined in both models (and not interchangeable). They also can be created only during object creation.public fun set_frozen_flag&amp;lt;T: key&amp;gt;(     ref: &amp;amp;TransferRef,     store: Object&amp;lt;T&amp;gt;,     frozen: bool, ) The Object TransferRef is used to transfer object ownership:/// Used to create LinearTransferRef, hence ownership transfer. struct TransferRef has drop, store {     self: address, } While the fungible asset&amp;#39;s TransferRef manages the transfer of fungible assets and the (un)freezing of fungible stores:/// TransferRef can be used to allow or disallow the owner of fungible assets from transferring the asset /// and allow the holder of TransferRef to transfer fungible assets from any account. struct TransferRef has drop, store {     metadata: Object&amp;lt;Metadata&amp;gt; } Additionally, there are fungible asset-specific references such as MintRef for minting and BurnRef for burning. These references are used exclusively by the fungible asset model, but they still must be created when the fungible asset object is initialized.Dispatchable fungible assetsDispatchable fungible assets enhance the functionality of fungible assets by enabling the overloading of operations like deposits and withdrawals.Hooks registered during the creation of a dispatchable fungible asset override the default logic for these operations, allowing for custom features like access control, fee mechanisms, or granular pausing.⚠️ WarningOverloading the core fungible asset functions introduces potential security risks; for example, during a deposit, funds may not end up at the intended address. The dispatchable fungible asset API provides functions like transfer_assert_minimum_deposit that can help mitigate such risks.Hook functions for dispatchable fungible assets must have the correct type signature. They must also be declared public to ensure their signature remains immutable. An example implementation might look like this:public fun withdraw_hook&amp;lt;T: key&amp;gt;(     store: Object&amp;lt;T&amp;gt;,     amount: u64,     transfer_ref: &amp;amp;TransferRef, ): FungibleAsset {     //check paused, gather fees etc.     fungible_asset::withdraw_with_ref(transfer_ref, store, amount) }  public fun deposit_hook&amp;lt;T: key&amp;gt;(     store: Object&amp;lt;T&amp;gt;,     fa: FungibleAsset,     transfer_ref: &amp;amp;TransferRef, ) {     //check paused, gather fees etc.     fungible_asset::deposit_with_ref(transfer_ref, store, fa); } QuestionWhy hook functions rely on *_with_ref calls? What would happen if the hook function called dispatchable_fungible_asset::withdraw instead of a fungible_asset::withdraw_with_ref?A1: Hook functions rely on *_with_ref calls because the default fungible asset functions verify if the fungible asset is not dispatchable.A2: A dispatchable_fungible_asset::withdraw would result in RUNTIME_DISPATCH_ERROR (code 4037) error with error message: &amp;quot;Re-entrancy detected&amp;quot;.In one of our reviews, we encountered a dispatchable fungible asset where the hooked withdrawal set a &amp;quot;blocked&amp;quot; flag, which was cleared by the corresponding deposit. This design was used to ensure that each withdrawal was tied to a deposit, effectively preventing simultaneous withdrawals.public fun deposit&amp;lt;T: key&amp;gt;(store: Object&amp;lt;T&amp;gt;, fa: FungibleAsset, transfer_ref: &amp;amp;TransferRef) {     assert_withdraw_flag(true);     [...]     set_withdraw_flag(false);     fungible_asset::deposit_with_ref(transfer_ref, store, amount);     [...]     }  public fun withdraw&amp;lt;T: key&amp;gt;(store: Object&amp;lt;T&amp;gt;, amount: u64, transfer_ref: &amp;amp;TransferRef): FungibleAsset acquires [...] {     assert_withdraw_flag(false);     [...]     set_withdraw_flag(true);     fungible_asset::withdraw_with_ref(transfer_ref, store, amount) } At first glance, this code appears valid, but not to an astute reader.QuestionCan you spot the bug? Hint: We mentioned the root cause previously.The developer overlooked an important detail, which we already mentioned earlier: a fungible asset with a value of zero can also be burned! An attacker could exploit this by withdrawing 0 FungibleAsset (since withdraw doesn’t verify if the value is greater than 0) and then burning it using fungible_asset::destroy_zero. This would complete the transaction while keeping the &amp;quot;blocked&amp;quot; flag set, effectively preventing further withdrawals.It&amp;#39;s important to understand all the features in the standard.Migrating from coins to fungible assetsIf a fungible asset is considered an upgrade to Coin, a transition mechanism becomes necessary. This is addressed through a conversion map, establishing a relationship between specific coin and fungible asset. This duality is not without its challenges.NoteWhile the Coin API recognizes and integrates with fungible assets, the fungible asset APIs do not have awareness of the linked Coin.The coin_to_fungible_asset converting function automatically generates a corresponding fungible asset for a Coin if one does not already exist. Manual creation of a fungible asset and its linkage to a Coin is not allowed.public fun coin_to_fungible_asset&amp;lt;CoinType&amp;gt;(     coin: Coin&amp;lt;CoinType&amp;gt; ): FungibleAsset acquires CoinConversionMap, CoinInfo {     let metadata = ensure_paired_metadata&amp;lt;CoinType&amp;gt;();     let amount = burn_internal(coin);     fungible_asset::mint_internal(metadata, amount) } When creating a fungible asset, several pieces of information are required, such as the asset’s name, symbol, or maximum supply. During our audit of the fungible asset standard, we noticed an overlooked detail in the linking process.[...] primary_fungible_store::create_primary_store_enabled_fungible_asset(     &amp;amp;metadata_object_cref,     option::map(coin_supply&amp;lt;CoinType&amp;gt;(), |_| MAX_U128),     name&amp;lt;CoinType&amp;gt;(),     symbol&amp;lt;CoinType&amp;gt;(),     decimals&amp;lt;CoinType&amp;gt;(),     string::utf8(b&amp;quot;&amp;quot;),     string::utf8(b&amp;quot;&amp;quot;), ); [...] When the linked fungible asset was created, the current Coin supply was incorrectly passed as the maximum fungible asset supply, preventing the minting of additional fungible assets beyond the existing coin circulation.Users can manually migrate their CoinStore to a primary fungible store. This creates a store for the paired fungible asset (if one doesn’t exist) and removes the &amp;lt;CoinStore&amp;lt;CoinType&amp;gt;&amp;gt; from the caller. All coins in the CoinStore are exchanged and transferred to the new store during the migration./// Voluntarily migrate to fungible store for `CoinType` if not yet. public entry fun migrate_to_fungible_store&amp;lt;CoinType&amp;gt;(     account: &amp;amp;signer ) acquires CoinStore, CoinConversionMap, CoinInfo {     maybe_convert_to_fungible_store&amp;lt;CoinType&amp;gt;(signer::address_of(account)); } A curious reader might wonder about the fate of the CoinStore &amp;quot;frozen&amp;quot; status during migration. Unsurprisingly tough, the &amp;quot;frozen&amp;quot; status of the primary fungible store is matched to that of the CoinStore to ensure consistency.QuestionCould an attacker convert their CoinStore to a primary fungible store and then register another CoinStore only to convert it again to manipulate the &amp;quot;frozen&amp;quot; status of the linked primary fungible store?The coin::register function first checks is_account_registered, which exits early if true. is_account_registered determines if the account has a primary fungible store for the linked fungible asset when the CoinStore doesn’t exist. If the fungible store has been converted, a primary fungible store and linked fungible asset will already exist, preventing re-registration.ConclusionAptos&amp;#39;s implementation of fungible assets does indeed resolve the original problems with Coin.However, this solution comes with its own challenges, in part because of the numerous layers that interact with each other. Before using the fungible asset standard, it&amp;#39;s important to understand these different APIs and potential pitfalls.As a final exercise to the reader, how many different ways are there to withdraw a fungible asset?1FootnotesThere are at least four functions that can withdraw a fungible asset:fungible_asset::withdrawdispatchable_fungible_asset::withdrawprimary_fungible_store::withdrawcoin::withdraw↩html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}</content>
    <link rel="enclosure" type="image/png" href="https://osec.io/posts/aptos-guide/title.png"/>
  </entry>
</feed>
