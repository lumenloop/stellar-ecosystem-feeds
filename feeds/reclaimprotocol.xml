<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
  <title type="text">Reclaim Protocol</title>
  <link rel="alternate" type="text/html" href="https://blog.reclaimprotocol.org/"/>
  <link rel="self" type="application/atom+xml" href="http://10.0.0.124:3044/?action=display&amp;bridge=CSSLostDateBridge&amp;home_page=https%3A%2F%2Fblog.reclaimprotocol.org%2F&amp;url_selector=.group.cursor-pointer+a&amp;url_pattern=posts%2F*.&amp;content_selector=article&amp;content_cleanup=h1%2C+article+.text-center%2C+.inline-block&amp;title_cleanup=&amp;date_selector=article+.text-center+div&amp;date_format=M+j%2C+Y&amp;date_selector_index=1&amp;author_selector=&amp;remove_styling=on&amp;remove_markup=on&amp;limit=3&amp;format=Atom"/>
  <icon>https://github.com/RSS-Bridge/rss-bridge/favicon.ico</icon>
  <logo>https://github.com/RSS-Bridge/rss-bridge/favicon.ico</logo>
  <id>http://10.0.0.124:3044/?action=display&amp;bridge=CSSLostDateBridge&amp;home_page=https%3A%2F%2Fblog.reclaimprotocol.org%2F&amp;url_selector=.group.cursor-pointer+a&amp;url_pattern=posts%2F*.&amp;content_selector=article&amp;content_cleanup=h1%2C+article+.text-center%2C+.inline-block&amp;title_cleanup=&amp;date_selector=article+.text-center+div&amp;date_format=M+j%2C+Y&amp;date_selector_index=1&amp;author_selector=&amp;remove_styling=on&amp;remove_markup=on&amp;limit=3&amp;format=Atom</id>
  <updated>2025-04-11T22:09:18+00:00</updated>
  <author>
    <name>RSS-Bridge</name>
  </author>
  <entry>
    <title type="html">Unpacking a Theoretical Attack on Reclaim Protocol (And Why It Doesn’t Stand a Chance)</title>
    <published>2025-03-13T22:09:18+00:00</published>
    <updated>2025-03-13T22:09:18+00:00</updated>
    <id>https://blog.reclaimprotocol.org/posts/one-theoretical-attack</id>
    <link rel="alternate" type="text/html" href="https://blog.reclaimprotocol.org/posts/one-theoretical-attack"/>
    <author>
      <name>Reclaim Protocol</name>
    </author>
    <content type="html">Cryptographic protocols often live in a constant battle between attackers and defenders, where new attack vectors are proposed, analyzed, and mitigated. One such discussion recently emerged around Reclaim Protocol. The proposed attack targets the protocol’s handling of AES-encrypted blocks, suggesting a potential vulnerability. In this post, we’ll dissect this attack, explain why Reclaim Protocol remains resilient, and estimate the computational resources required to execute it successfully with non-negligible probability. The Attack: Exploiting Key Consistency in AES Proofs Reclaim Protocol processes data in AES-encrypted blocks, typically using AES-GCM, and proves the content of each block independently via a ZK-SNARK circuit. The setup phase for Groth16 is circuit-dependent, but rather than generating a new trusted setup for every data size, Reclaim reuses a single AES circuit. This efficiency raises a question: how does the protocol ensure the same key is used across all blocks, especially when proofs are computed separately? The attack posits a “soundness-style” issue. In AES-GCM, a ciphertext ccc for a block of message message mmm is computed as c=AES(K,nonce)⊕mc=AES(K,nonce) \oplus mc=AES(K,nonce)⊕m , where KKK is the secret key, and the noncenoncenonce incorporates an initialization vector (IV). A malicious prover could select an arbitrary key K’≠KK’ \neq KK’=K and construct a proof for a manipulated message m’m’m’. For instance, they might compute AES(K’,nonce)⊕AES(K’,nonce)⊕AES(K,nonce)⊕mAES(K’,nonce) \oplus AES(K’,nonce) \oplus AES(K,nonce) \oplus mAES(K’,nonce)⊕AES(K’,nonce)⊕AES(K,nonce)⊕m which is equal to ccc due to the properties of the XOR function. This allows them to claim the ciphertext decrypts to a different message, m′=AES(K’,nonce)⊕AES(K,nonce)≠mm′= AES(K’,nonce) \oplus AES(K,nonce) \neq mm′=AES(K’,nonce)⊕AES(K,nonce)=m, which can be potentially a carefully crafted message that dependis on the adversary’s intent. At first glance, this seems to undermine the protocol’s integrity, as the ZKP could verify successfully for a false statement. However, the attack’s practical impact hinges on what the prover can achieve with this manipulation. Why Reclaim Protocol Remains Secure Reclaim’s resilience stems from two key factors:  The pseudorandomness of AES and its plaintext verification mechanism. AES is a block cipher whose output, under a different key, is indistinguishable from a random string unless the correct key is known. If a prover uses K’≠KK’ \neq KK’=K to decrypt the same cyphertext, the decrypted plaintext becomes a pseudorandom string. Which means that with a very high probability (which we will discuss later) this plaintext bears any meaningful data, and hence the adversary cannot possibly prove any intended claim (but rather an appearance of a random string at the website). Reclaim Protocol doesn’t merely verify the ZKP; it also checks that the plaintext contains the claimed data (e.g., an almost specific substring). Namely, we require each provider to be set up the way that the user discloses at least 16 bytes of the plaintext around the target data. This target substring is known in advance to an attestor, and hence, the user’s data either satisfies it, or the claim proof will not be approved by the attestor. Since the output of the manipulated decryption is gibberish, it cannot satisfy this semantic check.  Thus, while the attack allows a technically valid proof in isolation, it fails to produce a usable outcome. The cryptographic assumptions underpinning AES ensure that false proofs lack practical utility. Computational Resources Required for Success Could an adversary overcome this defense through brute force, finding a K’K’K’ that yields a meaningful plaintext with non-negligible probability? Let’s quantify this. AES-256 uses a 256-bit key, offering 22562^{256}2256 possible keys (approximately 107710^{77}1077). To succeed, an attacker must find a K’K’K’ such that AES(K’,nonce)⊕cAES(K’,nonce) \oplus cAES(K’,nonce)⊕c matches a target plaintext in at least 16 bytes. Current estimation of the global computational capacity is at roughly 102110^{21}1021 operations per second, combining all supercomputers and high-performance systems. So even assuming a single AES-256 decryption taking 1 operation (which is significantly less than in reality), testing all keys requires 107710^{77}1077 operations. At 102110^{21}1021 operations per second, this equates to 105610^{56}1056 seconds, or approximately 3×10483 \times 10^{48}3×1048 years. For context, the universe’s age is 1.38×10101.38 \times 10^{10}1.38×1010 years—meaning this effort would take about 103810^{38}1038 times the universe’s lifespan. Even optimizing with birthday paradox techniques (e.g., targeting a collision in a smaller plaintext space) barely dents this figure. In short, all the world’s supercomputers, operating in unison, would need to run for trillions of times the universe’s age to achieve a non-negligible success probability. Conclusion The proposed attack on Reclaim Protocol highlights an intriguing theoretical vulnerability: a malicious prover can craft a valid ZKP for a false statement by substituting keys. However, the protocol’s reliance on AES’s cryptographic strength renders this exploit impotent. The resulting plaintext from a fake key is random noise, failing to meet the system’s semantic requirements. With computational demands exceeding 104810^{48}1048 years using global resources, this attack remains a cryptographic curiosity rather than a practical threat. Reclaim Protocol stands firm, its security anchored in well-established primitives and thoughtful design.</content>
    <link rel="enclosure" type="image/png" href="https://blog.reclaimprotocol.org/blog/posts/one_theoretical_attack.png"/>
  </entry>
  <entry>
    <title type="html">OPRF Security Enhancements</title>
    <published>2025-03-10T22:09:18+00:00</published>
    <updated>2025-03-10T22:09:18+00:00</updated>
    <id>https://blog.reclaimprotocol.org/posts/oprf-security-enhancement</id>
    <link rel="alternate" type="text/html" href="https://blog.reclaimprotocol.org/posts/oprf-security-enhancement"/>
    <author>
      <name>Reclaim Protocol</name>
    </author>
    <content type="html">Special thanks to Aleksei Ermishkin for implementation and for valuable comments on this post. One of the key takeaways from our previous discussion on using T-OPRF for generating unique, per-user identifiers was the balance between privacy and verifiability. By leveraging a T-OPRF, we ensured that users could derive deterministic yet unlinkable IDs from their real-world identifiers, preventing impersonation and fraudulent reuse. However, in that approach, a single entity still had knowledge of critical secret values, introducing potential risks. Namely, Reclaim Protocol, as a dealer in T-OPRF, had a full knowledge of some secret values, further shared between T-OPRF servers. What if we could eliminate the need for any single party to hold a full secret, making the system inherently more resilient? In this post, we introduce key enhancements that achieve exactly that — ensuring that no one, including us, possesses complete knowledge of any secret key or value, fundamentally redefining the security and trust assumptions of the protocol.  Distributed Key Generation (DKG) is a cryptographic protocol used to generate a shared key among multiple participants in a distributed system. Unlike traditional key generation, where a single party generates and holds the private key (which can be further divided into shares for each of the parties), DKG ensures that no single entity has full control over the private key. Instead, the key is distributed among multiple parties who collaborate to generate it securely. Since there is no single entity in the world that knows the full key, this approach prevents any single party (or dealer) from being coerced by an adversary seeking to obtain the private key. In the case of Reclaim Protocol, previously, we acted as a dealer: generated a key and distributed it between T-OPRF servers. This mean that if an extremely powerful adversary wanted to learn the key, they could make us (e.g. legally) give it to them. However, by switching to the DKG mechanism that happens among T-OPRF servers, we annihilate this vulnerability. How Distributed Key Generation Works Step 1: Participant Initialization Each party in the system agrees to participate in the DKG protocol. There are nnn participants, and a threshold value ttt is set, meaning that at least ttt parties must collaborate to reconstruct the key. Step 2: Secret Sharing Each participant generates a secret sis_isi​ and uses Shamir’s Secret Sharing, to distribute shares of their secret among all other participants. Now, the key sss that the whole system will use (and that is unknown to any single party) is the sum of each of the participants’ secrets: s=s1+⋯+sns = s_1 + \dots + s_ns=s1​+⋯+sn​. Shamir&amp;#x27;s Secret Sharing (Brief Overview) Shamir&amp;#x27;s scheme allows a secret to be split into nnn shares such that at least ttt shares are required to reconstruct it. This is done using polynomial interpolation:  The secret sss is encoded as the constant term in a polynomial f(x)f(x)f(x) of degree t−1t-1t−1; Each participant iii receives a share f(i)f(i)f(i). Any ttt participants can use Lagrange interpolation to reconstruct sss, while fewer than ttt shares reveal no information about sss.  Each participant now holds a share of every other participant’s secret. Step 3: Usage of shares If a subset of at least ttt participants use each of the shares they received from other parties for T-OPRF, the combination of ttt output values (using Lagrange interpolation) will result into the output of OPRF using the secret sss.  When a client needs to compute their OPRF input we resort to hashing to a curve algorithm. So, in our case (and in general while working with elliptic curves in zero-knowledge proofs), efficiently representing curve points inside circuits is crucial. The BN254 twisted Edwards curve (Baby Jubjub) is commonly used in zk-SNARK applications due to its efficiency in circuits. Initially, we relied on scalar multiplication to generate points on the curve inside the circuit. However, later we found a more efficient approach: precomputing valid (X,Y)(X, Y)(X,Y) coordinates off-chain and passing a minimal counter value to reconstruct the point inside the circuit. Inthis section we explain why direct computation of X and Y is superior to scalar multiplication inside a circuit. Background: Curve Representation and Point Mapping Twisted Edwards Form: The Baby Jubjub curve is defined by the equation: ax2+y2=1+dx2y2,ax^2 + y^2 = 1 + dx^2y^2,ax2+y2=1+dx2y2, where (a,d)(a, d)(a,d) are curve parameters. Given a random scalar sss, there are two main ways to map it to a valid curve point:  Scalar Multiplication: Compute P=sGP = sGP=sG where GGG is a generator point. Direct Computation: Derive YYY from IDIDID and solve for XXX using the curve equation.  Why Scalar Multiplication is Inefficient Inside a Circuit Scalar multiplication sGsGsG involves performing multiple elliptic curve additions and doublings. Inside a zk-SNARK circuit, this is expensive due to:  Constraint Cost: Multiplications and additions in elliptic curve arithmetic introduce numerous constraints in zk-SNARK circuits. Bit Decomposition: The scalar sss must be decomposed into bits, leading to additional constraints. Variable-Time Computation: Different scalars lead to different computation paths, increasing proof generation complexity.  Security Concerns with Scalar Multiplication for Hashing to a Curve Aside from inefficiency, scalar multiplication also poses security concerns when used for hashing to a curve point. The primary issues include:  Non-Uniform Distribution: Scalar multiplication does not produce a uniform distribution of points on the curve, which is a requirement for secure cryptographic hashing; Knowledge of the scalar: The client that makes these computations knows the scalar value, thus endangering its security in the case of being corrupted (or armtwisted in the real world).  A More Efficient and Secure Approach: Precomputing X and Y Instead of computing sGsGsG inside the circuit, we explored precomputing valid curve coordinates offline. The process involves:  Hashed ID is used as a YYY coordinate (after a small number of iterations until the hash hits a possible value of YYY) Computing XXX using the curve equation. Passing only the counter value into the circuit, allowing the circuit to reconstruct the valid point deterministically.  This approach significantly reduces the in-circuit cost because ther is no scalar multiplication required anymore and the circuit only checks if (X,Y)(X, Y)(X,Y) satisfies the curve equation, thus reducing proof generation time. Moreover, now the client only knows some value of YYY such that (X,Y)(X,Y)(X,Y) is a valid point which, if gets corrupted, discloses no information, unlike the previously used value of the scalar sss.  By decentralizing secret management and eliminating any single party’s full knowledge of critical values, we take a significant step toward enhancing both security and trust in the protocol. This approach ensures that even Reclaim Protocol, or any other entity involved, cannot unilaterally reconstruct secret values, reducing the risk of compromise or coercion. By leveraging cryptographic techniques that distribute trust while preserving privacy and verifiability, we move closer to a system where users can generate deterministic yet unlinkable identifiers with stronger security guarantees. This shift fundamentally redefines the trust model, making the protocol not just more resilient but also more efficient.</content>
    <link rel="enclosure" type="image/png" href="https://blog.reclaimprotocol.org/blog/posts/oprf_security_enhancement.png"/>
  </entry>
  <entry>
    <title type="html">Use of OPRF to derive unique IDs</title>
    <published>2025-02-26T22:09:18+00:00</published>
    <updated>2025-02-26T22:09:18+00:00</updated>
    <id>https://blog.reclaimprotocol.org/posts/oprf-id-for-proofs</id>
    <link rel="alternate" type="text/html" href="https://blog.reclaimprotocol.org/posts/oprf-id-for-proofs"/>
    <author>
      <name>Reclaim Protocol</name>
    </author>
    <content type="html">Special thanks to Aleksei Ermishkin for the idea to use OPRF and for valuable comments on this post. Approach overview Many use cases of Reclaim require a unique, per-user identifier. This identifier must be binding, ensuring that users cannot share it with others or create multiple identifiers. Instead of generating a public key for each user, we use a natural identifier, such as a passport number or bank account number. Since we do not aim for a globally binding ID, each application is free to choose its own natural identifier. Moreover, once the application’s lifecycle ends, the identifier can be discarded. The challenge with this approach is that such identifiers are often sensitive and should remain hidden. Rather than using them directly, we derive a deterministic, unique identifier based on the selected natural ID. A naive approach would be to hash the natural ID and use the hash as the identifier. However, natural IDs often have low entropy (i.e., a limited number of possible values), making them vulnerable to brute-force attacks. To mitigate this risk, Reclaim Protocol leverages Oblivious Pseudorandom Functions (OPRFs). Understanding OPRFs and Threshold OPRFs An OPRF is an interactive protocol between a user and a OPRF server that computes a “salted hash” of the input such that:  The user does not learn the salt. The OPRF server does not learn anything about the user&amp;#x27;s input.  Formally, an OPRF allows a client to obtain the output of a pseudorandom function (PRF) on an input without revealing that input to the server. At the same time, the server, which participates in the computation, learns neither the input nor the output. This &amp;quot;oblivious&amp;quot; property enhances privacy.  A limitation of this approach is that a single entity controls the salt, which we aim to avoid. To address this, we use a decentralized variant known as Threshold OPRF (T-OPRF). A Threshold Oblivious Pseudorandom Function (T-OPRF) is a cryptographic primitive that extends the functionality of a traditional Oblivious Pseudorandom Function (OPRF) to support a threshold setting, enabling distributed and fault-tolerant computation. In a T-OPRF system, multiple servers collaborate to evaluate a PRF on a given input such that no single server learns the input or the PRF output, while a threshold subset of servers is sufficient to compute the result. In other words, instead of a single server performing the computation, a threshold number of participants collaborate to compute the function. This setup enhances security against individual server compromise. Summarizing the key features of T-OPRF:  The user learns the PRF output corresponding to their input data but nothing else about the PRF secret The servers learn neither the input provided by the user nor the resulting PRF output, nor the shares of other servers The PRF secret is shared across n servers using a secret sharing scheme and a minimum of t out of n servers are required to participate in the protocol to compute the PRF output The output of the PRF is independent of any individual server’s participation, ensuring that outputs cannot be linked back to specific protocol executions and is always the same for the same input data (regardless of the chosen servers)  How the T-OPRF Protocol Works Phases of the protocol:  Setup:  A secret key KKK is generated and distributed between nnn parties Each server holds a share of the secret key KKK, denoted as KiK_iKi​, while no single entity knows KKK entirely or any other share   Input Commitment:  The user generates a masked version X’X’X’ of their input ID XXX This masked input is sent to all nnn servers   Server Computation:  Each server computes a partial evaluation of the PRF, using their share KiK_iKi​ and the masked input X′X′X′ The server outputs a share of the blinded PRF result yi=FKi(X′)y_i=F_{K_i}(X′)yi​=FKi​​(X′), where FkF_kFk​ represents the PRF itself Additionally, each server outputs the so-called DLEQ proof that their computations were honest and correct   Aggregation and Reconstruction:  The user collects ttt or more shares yiy_iyi​ from the servers and verifies the correctness of each of the DLEQ proofs Using these shares, the user combines them and unmasks the input to reconstruct the final PRF output Fk(X)F_k(X)Fk​(X)    Deep dive into how T-OPRF works inside Reclaim tl;dr: this is a more formal description of how Reclaim Protocol exploits T-OPRF to prove an ownership of a unique ID in a zero-knowledge manner. Steps in Reclaim’s T-OPRF implementation:  The client performs T-OPRF for the ID they want to hide and prove, receiving t responses and (DLEQ) proofs for each of them that the computations were carried out correctly. The client verifies the proofs, combines the responses into one, and obtains the output value. The client provides to the zkTLS Attestor the following data: ZKP with the ciphertext, plaintext, encryption key, the position of the ID in the plaintext, and its length. Additionally, the client supplies t proofs and responses along with the final resulting output. The ZKP decrypts the ciphertext, extracts the ID at the specified position and length using a precomputed bitmask, and ensures that everything matches the provided output by verifying all DLEQ proofs and other checks.  Note that, the string hashed inside the ZKP is represented as two field elements of 31 bytes each, meaning the maximum string length for OPRF is 62 bytes. For OPRF operations, we use the babyjub curve, which operates efficiently inside the SNARK and is compatible with BN254. (Coming soon!) Handling key and OPRF servers updates Adding new nodes while keeping the same key is not secure because the previous cohort of nodes could censor the new ones. Therefore, whenever a new node is added, the key must be regenerated. Moreover, updating the key can be reasoned by any other business or security reason. And since we aim for static per-user IDs, changing the key would result in different identifiers. This is usually not an issue, as most applications require only short-term static IDs. Solution: Epochs To balance security and identifier stability, we introduce epochs — fixed timeframes (e.g., a month or a year) during which a user’s ID remains unchanged.  At the start of each new epoch, a new key is generated and distributed among an updated set of servers. In cases where older IDs need to persist beyond an epoch, servers retain previous key shares, allowing them to derive past identifiers upon request.  Adding OPRF mechanism to your provider using Reclaim Devtool To use the OPRF mechanism described above in a provider, one can follow the next steps (also, see the screenshots below):  Select Data: Click on the data you want to protect with OPRF, i.e. your ID; Enable OPRF: When adding a description, check the &amp;quot;private information&amp;quot; checkbox.   </content>
    <link rel="enclosure" type="image/png" href="https://blog.reclaimprotocol.org/blog/posts/oprf-id-for-proofs/cover.png"/>
  </entry>
</feed>
